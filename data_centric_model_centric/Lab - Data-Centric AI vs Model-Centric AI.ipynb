{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagopatriciosantos/dcai-lab/blob/master/data_centric_model_centric/Lab%20-%20Data-Centric%20AI%20vs%20Model-Centric%20AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e5916b2",
      "metadata": {
        "id": "0e5916b2"
      },
      "source": [
        "# Lab: Data-Centric vs Model-Centric approaches\n",
        "\n",
        "This lab gives an introduction to data-centric vs model-centric approaches to machine learning problems, showing how data-centric approaches can outperform purely model-centric approaches.\n",
        "\n",
        "In this lab, we'll build a classifier for product reviews (restricted to the magazine category), like:\n",
        "\n",
        "> Excellent! I look forward to every issue. I had no idea just how much I didn't know.  The letters from the subscribers are educational, too.\n",
        "\n",
        "Label: ⭐️⭐️⭐️⭐️⭐️ (good)\n",
        "\n",
        "> My son waited and waited, it took the 6 weeks to get delivered that they said it would but when it got here he was so dissapointed, it only took him a few minutes to read it.\n",
        "\n",
        "Label: ⭐️ (bad)\n",
        "\n",
        "We'll work with a dataset that has some issues, and we'll see how we can squeeze only so much performance out of the model by being clever about model choice, searching for better hyperparameters, etc. Then, we'll take a look at the data (as any good data scientist should), develop an understanding of the issues, and use simple approaches to improve the data. Finally, we'll see how improving the data can improve results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5874cd",
      "metadata": {
        "id": "2c5874cd"
      },
      "source": [
        "## Installing software\n",
        "\n",
        "For this lab, you'll need to install [scikit-learn](https://scikit-learn.org/) and [pandas](https://pandas.pydata.org/). If you don't have them installed already, you can install them by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e0ee93",
      "metadata": {
        "scrolled": true,
        "id": "a3e0ee93"
      },
      "outputs": [],
      "source": [
        "# !pip install scikit-learn pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27dbfce6",
      "metadata": {
        "id": "27dbfce6"
      },
      "source": [
        "# Loading the data\n",
        "\n",
        "First, let's load the train/test sets and take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7405df2c",
      "metadata": {
        "id": "7405df2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5a633542",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5a633542",
        "outputId": "facc5e74-528b-4474-9588-9bfeeae353dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                review label\n",
              "762  Trashy magazine written by trashy people. Comp...   bad\n",
              "405  My husband is really enjoying his subscription...  good\n",
              "389  This is the best magazine I've ever been subsc...  good\n",
              "599                   I haven't received an issue yet.   bad\n",
              "623                           Expected more substance.   bad"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e7bb788-0f63-4fbe-bd51-df3d0716f944\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>Trashy magazine written by trashy people. Comp...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>My husband is really enjoying his subscription...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>This is the best magazine I've ever been subsc...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>I haven't received an issue yet.</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>Expected more substance.</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e7bb788-0f63-4fbe-bd51-df3d0716f944')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e7bb788-0f63-4fbe-bd51-df3d0716f944 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e7bb788-0f63-4fbe-bd51-df3d0716f944');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_file=\"https://raw.githubusercontent.com/tiagopatriciosantos/dcai-lab/master/data_centric_model_centric/reviews_train.csv\"\n",
        "test_file = \"https://raw.githubusercontent.com/tiagopatriciosantos/dcai-lab/master/data_centric_model_centric/reviews_test.csv\"\n",
        "\n",
        "train = pd.read_csv(train_file )\n",
        "test = pd.read_csv(test_file)\n",
        "\n",
        "test.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6446a894",
      "metadata": {
        "id": "6446a894"
      },
      "source": [
        "# Training a baseline model\n",
        "\n",
        "There are many approaches for training a sequence classification model for text data. In this lab, we're giving you code that mirrors what you find if you look up [how to train a text classifier](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html), where we'll train an SVM on [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) features (numeric representations of each text field based on word occurrences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "26e13e03",
      "metadata": {
        "id": "26e13e03"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "afcb7dbd",
      "metadata": {
        "id": "afcb7dbd"
      },
      "outputs": [],
      "source": [
        "sgd_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "14a09cc6",
      "metadata": {
        "id": "14a09cc6"
      },
      "outputs": [],
      "source": [
        "_ = sgd_clf.fit(train['review'], train['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8885717d",
      "metadata": {
        "id": "8885717d"
      },
      "source": [
        "## Evaluating model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2850df30",
      "metadata": {
        "id": "2850df30"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "60677a08",
      "metadata": {
        "id": "60677a08"
      },
      "outputs": [],
      "source": [
        "def evaluate(clf):\n",
        "    pred = clf.predict(test['review'])\n",
        "    acc = metrics.accuracy_score(test['label'], pred)\n",
        "    print(f'Accuracy: {100*acc:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f77729fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f77729fb",
        "outputId": "4ebf87d7-bedc-4cf4-bba1-380d068f5318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.1%\n"
          ]
        }
      ],
      "source": [
        "evaluate(sgd_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3880fa",
      "metadata": {
        "id": "7d3880fa"
      },
      "source": [
        "## Trying another model\n",
        "\n",
        "76% accuracy is not great for this binary classification problem. Can you do better with a different model, or by tuning hyperparameters for the SVM trained with SGD?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70bdf2c7",
      "metadata": {
        "id": "70bdf2c7"
      },
      "source": [
        "# Exercise 1\n",
        "\n",
        "Can you train a more accurate model on the dataset (without changing the dataset)? You might find this [scikit-learn classifier comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) handy, as well as the [documentation for supervised learning in scikit-learn](https://scikit-learn.org/stable/supervised_learning.html).\n",
        "\n",
        "One idea for a model you could try is a [naive Bayes classifier](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
        "\n",
        "You could also try experimenting with different values of the model hyperparameters, perhaps tuning them via a [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). \n",
        "\n",
        "Or you can even try training multiple different models and [ensembling their predictions](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier), a strategy often used to win prediction competitions like Kaggle.\n",
        "\n",
        "**Advanced:** If you want to be more ambitious, you could try an even fancier model, like training a Transformer neural network. If you go with that, you'll want to fine-tune a pre-trained model. This [guide from HuggingFace](https://huggingface.co/docs/transformers/training) may be helpful."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhGYseEDNf26",
        "outputId": "2992683c-d3a0-4b6f-bb1a-346df7549025"
      },
      "id": "NhGYseEDNf26",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycaret[full] in /usr/local/lib/python3.8/dist-packages (2.3.10)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.23.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (3.5.3)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (3.7)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (3.2.2)\n",
            "Requirement already satisfied: numba<0.55 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.54.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.5.3)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.3.7)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (1.5.4)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.12.2)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (1.3.post1)\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.3)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (2.3.9)\n",
            "Requirement already satisfied: pyyaml<6.0.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (5.4.1)\n",
            "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.15.3)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.17.3)\n",
            "Requirement already satisfied: mlxtend>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.19.0)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (3.6.6)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (2.1.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (1.8.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.11.2)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (1.0.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (7.7.1)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (5.5.0)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (3.3.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (7.9.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (2.7.0)\n",
            "Collecting xgboost>=1.1.0\n",
            "  Using cached xgboost-1.7.4-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "Collecting autoviz\n",
            "  Using cached autoviz-0.1.58-py3-none-any.whl (64 kB)\n",
            "Collecting scikit-optimize>=0.8.1\n",
            "  Using cached scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "Collecting ray[tune]>=1.0.0\n",
            "  Using cached ray-2.3.0-cp38-cp38-manylinux2014_x86_64.whl (58.6 MB)\n",
            "Collecting evidently\n",
            "  Using cached evidently-0.2.5-py3-none-any.whl (12.1 MB)\n",
            "Collecting gradio\n",
            "  Using cached gradio-3.19.1-py3-none-any.whl (14.2 MB)\n",
            "Collecting fugue>=0.6.5\n",
            "  Using cached fugue-0.8.1-py3-none-any.whl (364 kB)\n",
            "Collecting fairlearn\n",
            "  Using cached fairlearn-0.8.0-py3-none-any.whl (235 kB)\n",
            "Collecting explainerdashboard\n",
            "  Using cached explainerdashboard-0.4.2.1-py3-none-any.whl (286 kB)\n",
            "Collecting catboost>=0.23.2\n",
            "  Using cached catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "Collecting interpret<=0.2.4\n",
            "  Using cached interpret-0.2.4-py3-none-any.whl (1.4 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.41.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (5.4.8)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.8/dist-packages (from pycaret[full]) (0.1.2)\n",
            "Collecting boto3\n",
            "  Using cached boto3-1.26.78-py3-none-any.whl (132 kB)\n",
            "Collecting tune-sklearn>=0.2.1\n",
            "  Using cached tune_sklearn-0.4.5-py3-none-any.whl (41 kB)\n",
            "Collecting optuna>=2.2.0\n",
            "  Using cached optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "Collecting azure-storage-blob\n",
            "  Using cached azure_storage_blob-12.15.0-py3-none-any.whl (387 kB)\n",
            "Collecting m2cgen\n",
            "  Using cached m2cgen-0.10.0-py3-none-any.whl (92 kB)\n",
            "Collecting uvicorn\n",
            "  Using cached uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "Collecting fastapi\n",
            "  Using cached fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn==0.7.0->pycaret[full]) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.23.2->pycaret[full]) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost>=0.23.2->pycaret[full]) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost>=0.23.2->pycaret[full]) (0.10.1)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret[full]) (57.4.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret[full]) (0.3.0)\n",
            "Collecting fugue-sql-antlr>=0.1.5\n",
            "  Using cached fugue-sql-antlr-0.1.5.tar.gz (154 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qpd>=0.4.0\n",
            "  Using cached qpd-0.4.0-py3-none-any.whl (187 kB)\n",
            "Collecting triad>=0.8.1\n",
            "  Using cached triad-0.8.2-py3-none-any.whl (71 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from fugue>=0.6.5->pycaret[full]) (2.11.3)\n",
            "Collecting adagio>=0.2.4\n",
            "  Using cached adagio-0.2.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (from fugue>=0.6.5->pycaret[full]) (1.4.46)\n",
            "Requirement already satisfied: pyarrow>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from fugue>=0.6.5->pycaret[full]) (9.0.0)\n",
            "Collecting sqlglot\n",
            "  Using cached sqlglot-11.2.3-py3-none-any.whl (233 kB)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim<4.0.0->pycaret[full]) (6.3.0)\n",
            "Collecting interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]>=0.2.4\n",
            "  Using cached interpret_core-0.3.0-py3-none-any.whl (8.9 MB)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret[full]) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret[full]) (3.0.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret[full]) (5.3.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret[full]) (3.6.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->pycaret[full]) (0.38.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (22.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (7.1.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret[full]) (4.38.0)\n",
            "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.8/dist-packages (from numba<0.55->pycaret[full]) (0.37.0)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Using cached cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog\n",
            "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna>=2.2.0->pycaret[full]) (1.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna>=2.2.0->pycaret[full]) (4.64.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pycaret[full]) (2022.7.1)\n",
            "Requirement already satisfied: ydata-profiling in /usr/local/lib/python3.8/dist-packages (from pandas-profiling>=2.8.0->pycaret[full]) (4.0.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.4.1->pycaret[full]) (8.2.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (22.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (7.1.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (4.3.3)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (1.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (1.0.4)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Using cached virtualenv-20.19.0-py3-none-any.whl (8.7 MB)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (1.51.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (3.9.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (2.28.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (3.19.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[tune]>=1.0.0->pycaret[full]) (0.8.10)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Using cached tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "Collecting pyaml>=16.9\n",
            "  Using cached pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (2.0.7)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (1.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (0.7.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (1.0.9)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (7.4.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (0.10.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret[full]) (1.0.2)\n",
            "Collecting pyamg\n",
            "  Using cached pyamg-4.2.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: fsspec>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from autoviz->pycaret[full]) (2023.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from autoviz->pycaret[full]) (4.5.0)\n",
            "Collecting hvplot>=0.7.3\n",
            "  Using cached hvplot-0.8.2-py2.py3-none-any.whl (3.2 MB)\n",
            "Collecting emoji\n",
            "  Using cached emoji-2.2.0.tar.gz (240 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: holoviews>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from autoviz->pycaret[full]) (1.14.9)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.8/dist-packages (from autoviz->pycaret[full]) (1.2.0)\n",
            "Collecting bokeh>=2.4.2\n",
            "  Using cached bokeh-3.0.3-py3-none-any.whl (16.5 MB)\n",
            "Collecting panel~=0.12.6\n",
            "  Using cached panel-0.12.7-py2.py3-none-any.whl (12.9 MB)\n",
            "Collecting jupyter\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from autoviz->pycaret[full]) (0.13.5)\n",
            "Collecting isodate>=0.6.1\n",
            "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "Collecting cryptography>=2.1.4\n",
            "  Using cached cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "Collecting azure-core<2.0.0,>=1.26.0\n",
            "  Using cached azure_core-1.26.3-py3-none-any.whl (174 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.78\n",
            "  Using cached botocore-1.29.78-py3-none-any.whl (10.4 MB)\n",
            "Collecting evidently\n",
            "  Using cached evidently-0.2.4-py3-none-any.whl (12.1 MB)\n",
            "  Using cached evidently-0.2.3-py3-none-any.whl (12.1 MB)\n",
            "  Using cached evidently-0.2.2-py3-none-any.whl (12.1 MB)\n",
            "  Using cached evidently-0.2.1-py3-none-any.whl (12.1 MB)\n",
            "Collecting dataclasses>=0.6\n",
            "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting evidently\n",
            "  Using cached evidently-0.2.0-py3-none-any.whl (12.1 MB)\n",
            "INFO: pip is looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting boto3\n",
            "  Using cached boto3-1.26.77-py3-none-any.whl (132 kB)\n",
            "INFO: pip is looking at multiple versions of boruta to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting Boruta\n",
            "  Using cached Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "  Using cached Boruta-0.2.2-py3-none-any.whl (56 kB)\n",
            "  Using cached Boruta-0.2.1-py3-none-any.whl (53 kB)\n",
            "  Using cached Boruta-0.2.0-py3-none-any.whl (53 kB)\n",
            "  Using cached Boruta-0.1.5.tar.gz (55 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Using cached Boruta-0.1.4.tar.gz (8.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Using cached Boruta-0.1.3.tar.gz (8.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of boruta to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached Boruta-0.1.2.tar.gz (10 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3ca681e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "3ca681e6",
        "outputId": "22fe4d13-e668-400d-cc3d-442f93ece4ba"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-68bb2f5aab00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycaret/classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_logger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mget_estimator_from_meta_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0;31m from pycaret.internal.pipeline import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0madd_estimator_to_pipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mget_pipeline_estimator_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycaret/internal/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_all_object_vars_and_properties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_fit_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/combine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/combine/_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_docstring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubstitution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_neighbors_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_kde\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKernelDensity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lof\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocalOutlierFactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_nca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeighborhoodComponentsAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVALID_METRICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVALID_METRICS_SPARSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_nca.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdict_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdict_learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_dict_learning\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pep562\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPep562\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_raise_dep_warning_if_not_pytest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdeprecated_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sklearn.decomposition.dict_learning'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_raise_dep_warning_if_not_pytest' from 'sklearn.utils.deprecation' (/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from pycaret.classification import *\n",
        "\n",
        "s = setup(train,target=\"label\" )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# evaluate your model and see if it does better\n",
        "# than the ones we provided"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a530ee43",
      "metadata": {
        "id": "a530ee43"
      },
      "source": [
        "## Taking a closer look at the training data\n",
        "\n",
        "Let's actually take a look at some of the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab34483c",
      "metadata": {
        "id": "ab34483c",
        "outputId": "b242be07-e358-4f84-d6b0-419bf17ca580"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Based on all the negative comments about Taste...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I still have not received this.  Obviously I c...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;/tr&gt;The magazine is not worth the cost of sub...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This magazine is basically ads. Kindve worthle...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The only thing I've recieved, so far, is the b...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review label\n",
              "0  Based on all the negative comments about Taste...  good\n",
              "1  I still have not received this.  Obviously I c...   bad\n",
              "2  </tr>The magazine is not worth the cost of sub...  good\n",
              "3  This magazine is basically ads. Kindve worthle...   bad\n",
              "4  The only thing I've recieved, so far, is the b...   bad"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db3c84e2",
      "metadata": {
        "id": "db3c84e2"
      },
      "source": [
        "Zooming in on one particular data point:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebf3a84",
      "metadata": {
        "id": "6ebf3a84",
        "outputId": "05a97441-d669-4005-b2e2-36f88a7cc6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'review': \"Based on all the negative comments about Taste of Home, I will not subscribeto the magazine. In the past it was a great read.\\nSorry it, too, has gone the 'way of the wind'.<br>o-p28pass4 </br>\", 'label': 'good'}\n"
          ]
        }
      ],
      "source": [
        "print(train.iloc[0].to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b839b33f",
      "metadata": {
        "id": "b839b33f"
      },
      "source": [
        "This data point is labeled \"good\", but it's clearly a negative review. Also, it looks like there's some funny HTML stuff at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e608bbc6",
      "metadata": {
        "id": "e608bbc6"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "Take a look at some more examples in the dataset. Do you notice any patterns with bad data points?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e43ff7",
      "metadata": {
        "id": "82e43ff7"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae38448f",
      "metadata": {
        "id": "ae38448f"
      },
      "source": [
        "## Issues in the data\n",
        "\n",
        "It looks like there's some funny HTML tags in our dataset, and those datapoints have nonsense labels. Maybe this dataset was collected by scraping the internet, and the HTML wasn't quite parsed correctly in all cases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664845e4",
      "metadata": {
        "id": "664845e4"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "To address this, a simple approach we might try is to throw out the bad data points, and train our model on only the \"clean\" data.\n",
        "\n",
        "Come up with a simple heuristic to identify data points containing HTML, and filter out the bad data points to create a cleaned training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5990cdcb",
      "metadata": {
        "id": "5990cdcb"
      },
      "outputs": [],
      "source": [
        "def is_bad_data(review: str) -> bool:\n",
        "    # YOUR CODE HERE\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "092849c1",
      "metadata": {
        "id": "092849c1"
      },
      "source": [
        "## Creating the cleaned training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c7671e",
      "metadata": {
        "id": "e9c7671e"
      },
      "outputs": [],
      "source": [
        "train_clean = train[~train['review'].map(is_bad_data)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1740bf3b",
      "metadata": {
        "id": "1740bf3b"
      },
      "source": [
        "## Evaluating a model trained on the clean training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e83abad",
      "metadata": {
        "id": "0e83abad"
      },
      "outputs": [],
      "source": [
        "from sklearn import clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e3c7d7",
      "metadata": {
        "id": "e5e3c7d7"
      },
      "outputs": [],
      "source": [
        "sgd_clf_clean = clone(sgd_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f72b0db",
      "metadata": {
        "id": "6f72b0db"
      },
      "outputs": [],
      "source": [
        "_ = sgd_clf_clean.fit(train_clean['review'], train_clean['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775ebff4",
      "metadata": {
        "id": "775ebff4"
      },
      "source": [
        "This model should do significantly better:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b78100",
      "metadata": {
        "id": "80b78100"
      },
      "outputs": [],
      "source": [
        "evaluate(sgd_clf_clean)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}